{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilable Classification: Classical Model Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import (accuracy_score, multilabel_confusion_matrix, \n",
    "                             ConfusionMatrixDisplay, classification_report, \n",
    "                             f1_score, recall_score, precision_score, \n",
    "                             roc_curve, roc_auc_score, hamming_loss, jaccard_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../assets/data/jigsaw_data\"\n",
    "\n",
    "print('Loading Development Data')\n",
    "dev = pd.read_csv(data_folder + \"/development_data.csv\")\n",
    "print('Done Loading Development Data')\n",
    "\n",
    "print('Loading Training Original Data')\n",
    "train_orig = pd.read_csv(data_folder + \"/train_original_data.csv\")\n",
    "print('Done Loading Training Original Data')\n",
    "\n",
    "print('Loading Training Augmented Data')\n",
    "train_aug = pd.read_csv(data_folder + \"/train_aug_data.csv\")\n",
    "print('Done Loading Training Augmented Data')\n",
    "\n",
    "print('Loading Validation Data')\n",
    "val = pd.read_csv(data_folder + \"/validation_data.csv\")\n",
    "print('Done Loading Validation Data')\n",
    "\n",
    "print('Loading Testing Data')\n",
    "test = pd.read_csv(data_folder + \"/test_data.csv\")\n",
    "print('Done Loading Testing Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_cols = ['id', 'comment_text', 'cleaned_comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'neutral']\n",
    "toxicity_classes = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig = train_orig[required_cols]\n",
    "train_aug = train_aug[required_cols]\n",
    "val = val[required_cols]\n",
    "test = test[required_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "X_train_orig = train_orig[\"cleaned_comment_text\"]\n",
    "y_train_orig = train_orig[toxicity_classes]\n",
    "\n",
    "X_train_orig.shape, y_train_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented\n",
    "X_train_aug = train_aug[\"cleaned_comment_text\"]\n",
    "y_train_aug = train_aug[toxicity_classes]\n",
    "\n",
    "X_train_aug.shape, y_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "X_val = val[\"cleaned_comment_text\"]\n",
    "y_val = val[toxicity_classes]\n",
    "\n",
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "X_test = test[\"cleaned_comment_text\"]\n",
    "y_test = test[toxicity_classes]\n",
    "\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_jaccard_score(y_true, y_pred):\n",
    "    jaccard = np.minimum(y_true, y_pred).sum(axis = 1)/np.maximum(y_true, y_pred).sum(axis = 1)\n",
    "    return jaccard.mean()*100\n",
    "\n",
    "def evaluate_model(X_train, y_train, X_val, y_val, X_test, y_test, y_pred_val, y_pred_test, classifier, clf):\n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(\"Clf: \", classifier.__class__.__name__)\n",
    "    model_results = {}\n",
    "    \n",
    "    model_results['Classifier'] = classifier.__class__.__name__\n",
    "    \n",
    "    model_results['Accuracy (train)'] = clf.score(X_train, y_train)\n",
    "    \n",
    "    # Validation Performance\n",
    "    model_results['Accuracy (val)'] = clf.score(X_val, y_val)\n",
    "    model_results['Accuracy (test)'] = clf.score(X_test, y_test)\n",
    "    \n",
    "    model_results['Recall (val)'] = recall_score(y_val, y_pred_val, average='weighted', labels=np.unique(y_pred_val))\n",
    "    model_results['Precision (val)'] = precision_score(y_val, y_pred_val, average='weighted', labels=np.unique(y_pred_val))\n",
    "    model_results['F1-score (val)'] = f1_score(y_val, y_pred_val, average='weighted', labels=np.unique(y_pred_val))\n",
    "    model_results['AUC-ROC (val)'] = roc_auc_score(y_val, y_pred_val)\n",
    "    model_results['Jacard score (val)'] = jaccard_score(y_val, y_pred_val,average='weighted', labels=np.unique(y_pred_test))\n",
    "    model_results['Hamming Loss (val)'] = hamming_loss(y_val, y_pred_val)\n",
    "    \n",
    "    model_results['CV Accuracy'] = cross_val_score(clf, X_train, y_train, cv=5).mean()\n",
    "    \n",
    "    # Test Performance\n",
    "    model_results['Recall (test)'] = recall_score(y_test, y_pred_test, average='weighted', labels=np.unique(y_pred_test))\n",
    "    model_results['Precision (test)'] = precision_score(y_test, y_pred_test, average='weighted', labels=np.unique(y_pred_test))\n",
    "    model_results['F1-score (test)'] = f1_score(y_test, y_pred_test, average='weighted', labels=np.unique(y_pred_test))\n",
    "    model_results['AUC-ROC (test)'] = roc_auc_score(y_test, y_pred_test)\n",
    "    model_results['Jacard score (test)'] = jaccard_score(y_test, y_pred_test, average='weighted', labels=np.unique(y_pred_test))\n",
    "    model_results['Hamming Loss (test)'] = hamming_loss(y_test, y_pred_test)\n",
    "\n",
    "    return model_results\n",
    "\n",
    "\n",
    "def run_model(classifier, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    model = OneVsRestClassifier(classifier)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    return model, y_pred_val, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_it(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # TFIDF Vectorizer\n",
    "    tfidf = TfidfVectorizer(analyzer='word', max_features=10000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "    # Vectorize X_train\n",
    "    X_train = tfidf.fit_transform(X_train)\n",
    "\n",
    "    # Vectorize X_val\n",
    "    X_val = tfidf.fit_transform(X_val)\n",
    "\n",
    "    # Vectorize X_test\n",
    "    X_test = tfidf.fit_transform(X_test)\n",
    "    \n",
    "    \n",
    "    model_benchmark = pd.DataFrame(columns=['Classifier', 'Accuracy (train)', 'Accuracy (val)', 'Accuracy (test)', 'CV Accuracy', \n",
    "                                            'Recall (val)', 'Precision (val)', 'F1-score (val)', 'AUC-ROC (val)', 'Jacard score (val)', 'Hamming Loss (val)',\n",
    "                                            'Recall (test)', 'Precision (test)', 'F1-score (test)', 'AUC-ROC (test)', 'Jacard score (test)', 'Hamming Loss (test)'\n",
    "                                           ])\n",
    "\n",
    "    sgd = SGDClassifier()\n",
    "    lr = LogisticRegression(solver='lbfgs')\n",
    "    svc = LinearSVC()\n",
    "    mnb = MultinomialNB()\n",
    "    dt = DecisionTreeClassifier()\n",
    "    gb = GradientBoostingClassifier()\n",
    "    ada = AdaBoostClassifier()\n",
    "    classifier_list = [sgd, lr, svc, mnb, dt, gb, ada]\n",
    "    models_object_list = []\n",
    "    \n",
    "    for classifier in classifier_list:        \n",
    "        clf, y_pred_val, y_pred_test = run_model(classifier, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "        model_result = evaluate_model(X_train, y_train, X_val, y_val, X_test, y_test, y_pred_val, y_pred_test, classifier, clf)\n",
    "        model_benchmark = model_benchmark.append(model_result, ignore_index=True)\n",
    "        \n",
    "        models_object_list.append(clf)\n",
    "\n",
    "    return model_benchmark, models_object_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_benchmark_Original, models_object_list_Original = run_it(X_train = X_train_orig, \n",
    "                                              y_train = y_train_orig,\n",
    "                                              X_val = X_val, \n",
    "                                              y_val = y_val, \n",
    "                                              X_test = X_test, \n",
    "                                              y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_benchmark_Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_predict = \"Arabs are committing genocide in Iraq, but no protests in Europe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word', max_features=10000, ngram_range=(1,3), stop_words='english')\n",
    "\n",
    "for model in models_object_list_Original:\n",
    "    \n",
    "    x = [text_to_predict]  \n",
    "\n",
    "    tfidf.fit_transform(X_train_orig)\n",
    "    xt = tfidf.transform(x)\n",
    "    print(model)\n",
    "    print(model.predict(xt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_benchmark_Augmented, models_object_list_Augmented = run_it(X_train = X_train_aug, \n",
    "                                  y_train = y_train_aug,\n",
    "                                  X_val = X_val, \n",
    "                                  y_val = y_val, \n",
    "                                  X_test = X_test, \n",
    "                                  y_test = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rearranged_columns=['Classifier', 'Accuracy (train)', 'Accuracy (val)', 'Accuracy (test)', 'CV Accuracy', \n",
    "         'Recall (val)','Recall (test)', 'Precision (val)', 'Precision (test)', 'F1-score (val)', 'F1-score (test)',\n",
    "         'AUC-ROC (val)', 'AUC-ROC (test)', 'Jacard score (val)', 'Jacard score (test)', 'Hamming Loss (val)', 'Hamming Loss (test)'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_benchmark_Original[rearranged_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_benchmark_Augmented[rearranged_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
